{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "import boto3\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "getattr(tqdm, '_instances', {}).clear()  # â¬… add this line\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # save images\n",
    "import time # get time stamp of models trained\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab and resize image from and to s3 bucket\n",
    "\n",
    "img_dir = 'new_images' # folder containing all other folders of images\n",
    "\n",
    "\n",
    "def resize_images_array(img_dir, file_paths):\n",
    "    # arrays of image pixels\n",
    "    img_arrays = []\n",
    "    \n",
    "    # loop through the dataframe that is linked to its label so that all images are in the same order\n",
    "    for path in tqdm(file_paths):\n",
    "        s3 = boto3.client('s3')\n",
    "        try:\n",
    "            obj = s3.get_object(Bucket=bucket, Key=f'{img_dir}/{path}')\n",
    "            img_bytes = BytesIO(obj['Body'].read())\n",
    "            open_img = Image.open(img_bytes)\n",
    "            arr = np.array(open_img.resize((200,200))) # resize to 200,200. possible to play around with better or worse resolution\n",
    "            img_arrays.append(arr)\n",
    "        except:\n",
    "#             print(path) # get file_path of ones that fail to load\n",
    "            continue\n",
    "\n",
    "    return np.array(img_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = resize_images_array()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_img = \n",
    "single_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = s3.get_object(Bucket=bucket, Key=f'images/0776/16398b734cf540e3b0bcc943621e3515.jpg')\n",
    "img_bytes = BytesIO(obj['Body'].read())\n",
    "open_img = Image.open(img_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By stacking these together into a 3-tensor, we can represent a color image as a single object.\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16,6))\n",
    "\n",
    "axes[0].imshow(open_img)\n",
    "axes[0].set_title('original')\n",
    "for ax, channel, name in zip(axes[1:], open_img.split(), ['red channel', 'green channel', 'blue channel']):\n",
    "    ax.imshow(channel)\n",
    "    ax.set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Feature Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the RBG values\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ['duck', 'hawk', 'finch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label shape: ', y.shape)\n",
    "print('features shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure the bird images and labels are aligned\n",
    "# this is indeed a semipalmated sandpiper\n",
    "\n",
    "print()\n",
    "plt.imshow(X[57]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work Flow\n",
    "\n",
    "1. X, and y defined\n",
    "- make sure they are arrays!!\n",
    "\n",
    "2. normalize X values by dividing by 255\n",
    "3. check images\n",
    "4. train test split\n",
    "5. make model Sequential()\n",
    "6. add input layer\n",
    "7. add multiple hidden layers\n",
    "8. ADD FLATTEN LAYER, MUST BE BEFORE OUTPUT\n",
    "9. add dense layer, which are fully connected layers\n",
    "10. add output dense layer, will be the amount of labels there are\n",
    "11. model.compile(loss = 'sparse_categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "12. model.fit(xtrain, ytrain, epochs) also has validation_split (out of sample) do about 0.1, batchsize: how many at a time, more data requires bigger (20-200 range)\n",
    "13. model.evaluate(xtest,ytest) returns val loss and val accuracy  \n",
    "\n",
    "14. model.save('name') saves the model\n",
    "- to load: new_model = tf.keras.models.load_model('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras and tensorflow downloads\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization # CNN\n",
    "from tensorflow.keras.callbacks import TensorBoard # graphical visual of loss and accuracy over the epochs of train and test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[55]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN: Convolutional Neural Network Modelx 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model1 = Sequential()\n",
    "\n",
    "# Convolution Layer\n",
    "modelx1.add(Conv2D(32, (3,3), activation='relu', input_shape=X_train[0].shape)) # scans with a (3,3) grid\n",
    "modelx1.add(BatchNormalization())\n",
    "modelx1.add(MaxPool2D(2,2)) # grid to pool together the first grid\n",
    "modelx1.add(Dropout(0.3))\n",
    "\n",
    "modelx1.add(Conv2D(64, (3,3), activation='relu')) # scans with a (3,3) grid\n",
    "modelx1.add(BatchNormalization())\n",
    "modelx1.add(MaxPool2D(2,2)) # grid to pool together the first grid\n",
    "modelx1.add(Dropout(0.3))\n",
    "\n",
    "modelx1.add(Conv2D(128, (3,3), activation='relu')) # scans with a (3,3) grid\n",
    "modelx1.add(BatchNormalization())\n",
    "modelx1.add(MaxPool2D(2,2)) # grid to pool together the first grid\n",
    "modelx1.add(Dropout(0.4))\n",
    "\n",
    "# Must Flatten before entering Dense layers\n",
    "modelx1.add(Flatten())\n",
    "\n",
    "modelx1.add(Dense(128, activation='relu'))\n",
    "modelx1.add(BatchNormalization())\n",
    "modelx1.add(Dropout(0.4))\n",
    "\n",
    "modelx1.add(Dense(128, activation='relu'))\n",
    "modelx1.add(BatchNormalization())\n",
    "modelx1.add(Dropout(0.4))\n",
    "\n",
    "modelx1.add(Dense(y_train.shape[1], activation='softmax')) # have to have same amount as y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Modelx 1: CNN')\n",
    "print(f'Number of Training Images: {X_train.shape[0]}/{X_train.shape[0] + X_test.shape[0]}')\n",
    "modelx1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelx1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs/fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Modelx 1: CNN')\n",
    "print(f'Number of Training Images: {X_train.shape[0]}/{X_train.shape[0] + X_test.shape[0]}')\n",
    "historyx1 = modelx1.fit(X_train, y_train, batch_size = 100, epochs=10, validation_split=0.1, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyx1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "epoch_range = range(1, 11)\n",
    "\n",
    "axes[0].plot(epoch_range, historyx1.history['accuracy'])\n",
    "axes[0].plot(epoch_range, historyx1.history['val_accuracy'])\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_xlabel('Number of Epochs')\n",
    "axes[0].legend(['Train', 'Val'], loc='upper left')\n",
    "axes[0].set_title('Modelx1 Accuracy')\n",
    "\n",
    "axes[1].plot(epoch_range, historyx1.history['loss'])\n",
    "axes[1].plot(epoch_range, historyx1.history['val_loss'])\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_xlabel('Number of Epochs')\n",
    "axes[1].legend(['Train', 'Val'], loc='upper left')\n",
    "axes[1].set_title('Modelx1 Loss')\n",
    "\n",
    "plt.savefig('graphs/modelx1_acc_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "\n",
    "# %tensorboard --logdir='logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = modelx1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CNN Model 1 Prediction Check: ')\n",
    "print('True label of bird: ',)\n",
    "print('Predicted label of bird: ', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelx1.save('saved_models/conv-3-dense-2-fr32-128.h5')\n",
    "# keras.models.load_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
