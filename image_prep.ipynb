{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import random\n",
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "import boto3\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Visualize the images and their annotations\n",
    "# image_identifiers = list(image_paths.keys())\n",
    "# random.shuffle(image_identifiers) \n",
    "# for image_id in image_identifiers:\n",
    "#     image_path = image_paths[image_id]\n",
    "#     image = plt.imread(image_path)\n",
    "#     bbox = image_bboxes[image_id]\n",
    "#     parts = image_parts[image_id]\n",
    "#     class_label = image_class_labels[image_id]\n",
    "#     class_name = class_names[class_label]\n",
    "      \n",
    "#     # Render the image\n",
    "#     plt.close(1)\n",
    "#     fig = plt.figure(1, figsize=(16, 12))\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(\"Image ID: %s \\n Class Label: %s  [ID: %s]\" % (image_id, class_name, class_label))\n",
    "      \n",
    "#     # Render the bounding box annotations\n",
    "#     bbox_x, bbox_y, bbox_width, bbox_height = bbox\n",
    "#     currentAxis = plt.gca()\n",
    "#     currentAxis.add_patch(plt.Rectangle((bbox_x , bbox_y), bbox_width, bbox_height, facecolor=\"green\", alpha=0.3))\n",
    "      \n",
    "#     # Render the part annotations\n",
    "#     if has_networkx:\n",
    "#     # Use networkx spring layout\n",
    "        \n",
    "#         G = nx.Graph()\n",
    "#         part_data = []\n",
    "#         initial_positions = {}\n",
    "#         for part_id, part in enumerate(parts):\n",
    "#             x, y, v = part\n",
    "#             if v:\n",
    "#                 part_str = 'part_%d' % (part_id,)\n",
    "#                 label_str = 'label_%d' % (part_id,)\n",
    "            \n",
    "#                 G.add_node(part_str)\n",
    "#                 G.add_node(label_str)\n",
    "#                 G.add_edge(part_str, label_str)\n",
    "            \n",
    "#                 part_data.append(part_str)\n",
    "            \n",
    "#                 initial_positions[part_str] = (x, y)\n",
    "#                 initial_positions[label_str] = (x, y)\n",
    "            \n",
    "#             positions = nx.spring_layout(G, dim=2, k=20.0, pos=initial_positions, fixed=part_data)\n",
    "        \n",
    "#             for part_id, part in enumerate(parts):\n",
    "#                 x, y, v = part\n",
    "#                 if v:\n",
    "#                     plt.plot(x, y, 'o')\n",
    "            \n",
    "#                     label_str = 'label_%d' % (part_id,)\n",
    "#                     label_position = positions[label_str]\n",
    "#                     label_xy = (label_position[0] * bbox_width + bbox_x, label_position[1] * bbox_height + bbox_y)\n",
    "#                     plt.annotate(\n",
    "#                       part_names[part_id], \n",
    "#                       xy=(x, y),\n",
    "#                       xycoords='data', \n",
    "#                       xytext= label_xy, \n",
    "#                       textcoords='data',\n",
    "#                       ha='right', \n",
    "#                       va='bottom',\n",
    "#                       bbox=dict(boxstyle= 'round,pad=0.5', \n",
    "#                             fc='yellow', \n",
    "#                             alpha=0.5),\n",
    "#                       arrowprops=dict(arrowstyle='->', \n",
    "#                               connectionstyle='arc3,rad=0')\n",
    "#                     )\n",
    "    \n",
    "#                 else:\n",
    "#                     # just a basic label annotation for the part locations\n",
    "#                     offset = (2 * math.pi) / len(parts)\n",
    "#                     for part_id, part in enumerate(parts):\n",
    "#                         x, y, v = part\n",
    "#                         if v: \n",
    "#                             # try to offset the part labels so that they don't overlap too badly\n",
    "#                             dist = random.randint(35, 65)\n",
    "#                             offset_x = dist * math.cos(offset * part_id)\n",
    "#                             offset_y = dist * math.sin(offset * part_id)\n",
    "          \n",
    "#                             plt.plot(x, y, 'o')\n",
    "#                             plt.annotate(\n",
    "#                               part_names[part_id], \n",
    "#                               xy=(x, y), \n",
    "#                               xytext=(offset_x, offset_y), \n",
    "#                               textcoords='offset points', \n",
    "#                               ha='right', \n",
    "#                               va='bottom',\n",
    "#                               bbox=dict(boxstyle= 'round,pad=0.5', \n",
    "#                                 fc='yellow', \n",
    "#                                 alpha=0.5),\n",
    "#                               arrowprops=dict(arrowstyle='->', \n",
    "#                                   connectionstyle='arc3,rad=0')\n",
    "#                             )\n",
    "  \n",
    "#     plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def rename_multiple_files(path,obj):\n",
    "\n",
    "#     i=0\n",
    "\n",
    "#     for filename in os.listdir(path):\n",
    "#         try:\n",
    "#             f,extension = os.path.splitext(path+filename)\n",
    "#             src=path+'/'+filename\n",
    "#             dst=path+'/'+obj+str(i)+extension\n",
    "#             os.rename(src,dst)\n",
    "#             i+=1\n",
    "#             print('Rename successful.')\n",
    "#         except:\n",
    "#             i+=1\n",
    "\n",
    "# path='training_set'\n",
    "# obj=f\"{src_path.split('.')[1]}\"\n",
    "# rename_multiple_files(path,obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras and tensorflow downloads\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D # CNN\n",
    "from tensorflow.keras.callbacks import TensorBoard # graphical visual of loss and accuracy over the epochs of train and test set\n",
    "\n",
    "import pickle # save images\n",
    "import time # get time stamp of models trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import text files (image names, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg # show images\n",
    "from io import BytesIO # reading bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe with images.txt\n",
    "\n",
    "_Contains name of images and file path_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'cwbirdsimages'\n",
    "img_dir = 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "img_txt = s3.get_object(Bucket=bucket, Key='images.txt')\n",
    "\n",
    "img_names = BytesIO(img_txt['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(img_names, header=None, low_memory=False, na_values='n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['file_path'] = data[0].apply(lambda x: x.split()[1])\n",
    "data['img_name'] = data[0].apply(lambda x: x.split()[0])\n",
    "\n",
    "data['folder_num'] = data['file_path'].apply(lambda x: x.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>img_name</th>\n",
       "      <th>folder_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0817/0000139e21dc4d0cbfe14cae3c85c829.jpg</td>\n",
       "      <td>0000139e-21dc-4d0c-bfe1-4cae3c85c829</td>\n",
       "      <td>0817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0860/0000d9fc4e024c06a0afa55cfb16b12b.jpg</td>\n",
       "      <td>0000d9fc-4e02-4c06-a0af-a55cfb16b12b</td>\n",
       "      <td>0860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0900/000193069d834334b255a447742edce3.jpg</td>\n",
       "      <td>00019306-9d83-4334-b255-a447742edce3</td>\n",
       "      <td>0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0645/0001afd499a14a67b940d419413e23b3.jpg</td>\n",
       "      <td>0001afd4-99a1-4a67-b940-d419413e23b3</td>\n",
       "      <td>0645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0929/000332b8997c454096472f0a8495aecf.jpg</td>\n",
       "      <td>000332b8-997c-4540-9647-2f0a8495aecf</td>\n",
       "      <td>0929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48557</th>\n",
       "      <td>0891/fff86e8b795f400a91e8565bbb8c453a.jpg</td>\n",
       "      <td>fff86e8b-795f-400a-91e8-565bbb8c453a</td>\n",
       "      <td>0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48558</th>\n",
       "      <td>0660/fff926d7ccad4788839e97af2dd99372.jpg</td>\n",
       "      <td>fff926d7-ccad-4788-839e-97af2dd99372</td>\n",
       "      <td>0660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48559</th>\n",
       "      <td>0492/fffa33efa765408d8d666efc7f504c71.jpg</td>\n",
       "      <td>fffa33ef-a765-408d-8d66-6efc7f504c71</td>\n",
       "      <td>0492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48560</th>\n",
       "      <td>0372/ffff0d87bc844ef2a47ea4bfa48502ce.jpg</td>\n",
       "      <td>ffff0d87-bc84-4ef2-a47e-a4bfa48502ce</td>\n",
       "      <td>0372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48561</th>\n",
       "      <td>0880/fffff3a52a7547d0887f03871e3f9a37.jpg</td>\n",
       "      <td>fffff3a5-2a75-47d0-887f-03871e3f9a37</td>\n",
       "      <td>0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48562 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file_path  \\\n",
       "0      0817/0000139e21dc4d0cbfe14cae3c85c829.jpg   \n",
       "1      0860/0000d9fc4e024c06a0afa55cfb16b12b.jpg   \n",
       "2      0900/000193069d834334b255a447742edce3.jpg   \n",
       "3      0645/0001afd499a14a67b940d419413e23b3.jpg   \n",
       "4      0929/000332b8997c454096472f0a8495aecf.jpg   \n",
       "...                                          ...   \n",
       "48557  0891/fff86e8b795f400a91e8565bbb8c453a.jpg   \n",
       "48558  0660/fff926d7ccad4788839e97af2dd99372.jpg   \n",
       "48559  0492/fffa33efa765408d8d666efc7f504c71.jpg   \n",
       "48560  0372/ffff0d87bc844ef2a47ea4bfa48502ce.jpg   \n",
       "48561  0880/fffff3a52a7547d0887f03871e3f9a37.jpg   \n",
       "\n",
       "                                   img_name folder_num  \n",
       "0      0000139e-21dc-4d0c-bfe1-4cae3c85c829       0817  \n",
       "1      0000d9fc-4e02-4c06-a0af-a55cfb16b12b       0860  \n",
       "2      00019306-9d83-4334-b255-a447742edce3       0900  \n",
       "3      0001afd4-99a1-4a67-b940-d419413e23b3       0645  \n",
       "4      000332b8-997c-4540-9647-2f0a8495aecf       0929  \n",
       "...                                     ...        ...  \n",
       "48557  fff86e8b-795f-400a-91e8-565bbb8c453a       0891  \n",
       "48558  fff926d7-ccad-4788-839e-97af2dd99372       0660  \n",
       "48559  fffa33ef-a765-408d-8d66-6efc7f504c71       0492  \n",
       "48560  ffff0d87-bc84-4ef2-a47e-a4bfa48502ce       0372  \n",
       "48561  fffff3a5-2a75-47d0-887f-03871e3f9a37       0880  \n",
       "\n",
       "[48562 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame of image_class_labels.txt\n",
    "\n",
    "_Contains name of image file and corresponding folder number_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "img_txt = s3.get_object(Bucket=bucket, Key='image_class_labels.txt')\n",
    "\n",
    "img_class_labels = BytesIO(img_txt['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(img_class_labels, header=None, low_memory=False, na_values='n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000139e-21dc-4d0c-bfe1-4cae3c85c829 817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000d9fc-4e02-4c06-a0af-a55cfb16b12b 860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00019306-9d83-4334-b255-a447742edce3 900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001afd4-99a1-4a67-b940-d419413e23b3 645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000332b8-997c-4540-9647-2f0a8495aecf 929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48557</th>\n",
       "      <td>fff86e8b-795f-400a-91e8-565bbb8c453a 891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48558</th>\n",
       "      <td>fff926d7-ccad-4788-839e-97af2dd99372 660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48559</th>\n",
       "      <td>fffa33ef-a765-408d-8d66-6efc7f504c71 492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48560</th>\n",
       "      <td>ffff0d87-bc84-4ef2-a47e-a4bfa48502ce 372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48561</th>\n",
       "      <td>fffff3a5-2a75-47d0-887f-03871e3f9a37 880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48562 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0\n",
       "0      0000139e-21dc-4d0c-bfe1-4cae3c85c829 817\n",
       "1      0000d9fc-4e02-4c06-a0af-a55cfb16b12b 860\n",
       "2      00019306-9d83-4334-b255-a447742edce3 900\n",
       "3      0001afd4-99a1-4a67-b940-d419413e23b3 645\n",
       "4      000332b8-997c-4540-9647-2f0a8495aecf 929\n",
       "...                                         ...\n",
       "48557  fff86e8b-795f-400a-91e8-565bbb8c453a 891\n",
       "48558  fff926d7-ccad-4788-839e-97af2dd99372 660\n",
       "48559  fffa33ef-a765-408d-8d66-6efc7f504c71 492\n",
       "48560  ffff0d87-bc84-4ef2-a47e-a4bfa48502ce 372\n",
       "48561  fffff3a5-2a75-47d0-887f-03871e3f9a37 880\n",
       "\n",
       "[48562 rows x 1 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0000139e-21dc-4d0c-bfe1-4cae3c85c829 817'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df['img_name'] = labels_df[0].apply(lambda x: x.split()[1])\n",
    "labels_df[''] = labels_df[0].apply(lambda x: x.split()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=f'{img_path}/0295/01f53d6bf5e449438d2bb79e0854bca4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = BytesIO(obj['Body'].read())\n",
    "im = mpimg.imread(data, 'jpg')\n",
    "\n",
    "plt.figure(0)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_data = []\n",
    "#     for filename in csv_files:\n",
    "#         s3 = boto3.client('s3')\n",
    "#         obj = s3.get_object(Bucket=bucket, Key=filename)\n",
    "#         data = obj['Body'].read()\n",
    "#         f = BytesIO(data)\n",
    "#         data = pd.read_csv(f, header=1, low_memory=False, na_values='n/a',\n",
    "#                            usecols=columns, nrows=number_of_rows) \n",
    "#         loan_data.append(data)\n",
    "#     loans = pd.concat(loan_data)\n",
    "#     # Loan IDs are unique and we can access specific loans much faster by setting them as the index.\n",
    "#     #loans.set_index('id', inplace=True)\n",
    "#     return loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def resize_multiple_images(src_folder, dst_path):\n",
    "    # src_folder is the location where images are saved\n",
    "    for dirpath, dirnames, filenames in os.walk(src_folder):\n",
    "        for filename in os.listdir(dirpath):\n",
    "            try:\n",
    "                img=Image.open(filename+'.jpg')\n",
    "                new_img = img.resize((64,64))\n",
    "                if not os.path.exists(dst_path):\n",
    "                    os.makedirs(dst_path)\n",
    "                new_img.save(dst_path+'/'+filename)\n",
    "                print('Resized and saved {}.'.format(filename))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "# src_folder = 'images'\n",
    "# dst_path = 'resized_images'\n",
    "# resize_multiple_images(src_folder, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def get_data(path):\n",
    "    all_images_as_array=[]\n",
    "    label=[]\n",
    "    for filename in os.listdir(path):\n",
    "        try:\n",
    "            if re.match(r'Black_footed_Albatross',filename):\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "            img=Image.open(path + '/'+ filename)\n",
    "            np_array = np.asarray(img)\n",
    "            l,b,c = np_array.shape\n",
    "            np_array = np_array.reshape(l*b*c,)\n",
    "            all_images_as_array.append(np_array)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return np.array(all_images_as_array), np.array(label)\n",
    "\n",
    "# path_to_train_set = 'train_set/'\n",
    "# path_to_test_set = 'test_set/'\n",
    "# X_train,y_train = get_data(path_to_train_set)\n",
    "# X_test, y_test = get_data(path_to_test_set)\n",
    "\n",
    "# print('X_train set : ',X_train)\n",
    "# print('y_train set : ',y_train)\n",
    "# print('X_test set : ',X_test)\n",
    "# print('y_test set : ',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def load_bounding_box_annotations(dataset_path=''):\n",
    "#     bboxes = {}\n",
    "#     with open(os.path.join(dataset_path, 'bounding_boxes.txt')) as f:\n",
    "#         for line in f:\n",
    "#             pieces = line.strip().split()\n",
    "#             image_id = pieces[0]\n",
    "#             bbox = map(int, pieces[1:])\n",
    "#             bboxes[image_id] = bbox\n",
    "#     return bboxes\n",
    "\n",
    "# def load_part_annotations(dataset_path=''):\n",
    "#     parts = {}\n",
    "#     with open(os.path.join(dataset_path, 'parts/part_locs.txt')) as f:\n",
    "#         for line in f:\n",
    "#             pieces = line.strip().split()\n",
    "#             image_id = pieces[0]\n",
    "#             parts.setdefault(image_id, [0] * 11)\n",
    "#             part_id = int(pieces[1])\n",
    "#             parts[image_id][part_id] = [int(x) for x in pieces[2:]]\n",
    "#     return parts  \n",
    "  \n",
    "# def load_part_names(dataset_path=''):\n",
    "#     names = {}\n",
    "#     with open(os.path.join(dataset_path, 'parts/parts.txt')) as f:\n",
    "#         for line in f:\n",
    "#             pieces = line.strip().split()\n",
    "#             part_id = int(pieces[0])\n",
    "#             names[part_id] = ' '.join(pieces[1:])\n",
    "#     return names  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class_names(dataset_path=''):\n",
    "    names = {}\n",
    "    with open(os.path.join(dataset_path, 'classes.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            class_id = pieces[0]\n",
    "            names[class_id] = ' '.join(pieces[1:])\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_labels(dataset_path=''):\n",
    "    labels = {}\n",
    "    with open(os.path.join(dataset_path, 'image_class_labels.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            image_id = pieces[0]\n",
    "            class_id = pieces[1]\n",
    "            labels[image_id] = class_id\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def load_image_paths(dataset_path='', path_prefix=''):\n",
    "    paths = {}\n",
    "    with open(os.path.join(dataset_path, 'images.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            image_id = pieces[0]\n",
    "            path = os.path.join(path_prefix, pieces[1])\n",
    "            paths[image_id] = path\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_sizes(dataset_path=''):\n",
    "    sizes = {}\n",
    "    with open(os.path.join(dataset_path, 'sizes.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            image_id = pieces[0]\n",
    "            width, height = map(int, pieces[1:])\n",
    "            sizes[image_id] = [width, height]\n",
    "    return sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hierarchy(dataset_path=''):\n",
    "    parents = {}\n",
    "    with open(os.path.join(dataset_path, 'hierarchy.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            child_id, parent_id = pieces\n",
    "            parents[child_id] = parent_id\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_split(dataset_path=''):\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    with open(os.path.join(dataset_path, 'train_test_split.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            image_id = pieces[0]\n",
    "            is_train = int(pieces[1])\n",
    "            if is_train:\n",
    "                train_images.append(image_id)\n",
    "            else:\n",
    "                test_images.append(image_id)\n",
    "    return train_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def load_photographers(dataset_path=''):\n",
    "#     photographers = {}\n",
    "#     with open(os.path.join(dataset_path, 'photographers.txt')) as f:\n",
    "#         for line in f:\n",
    "#             pieces = line.strip().split()\n",
    "#             image_id = pieces[0]\n",
    "#             photographers[image_id] = ' '.join(pieces[1:])\n",
    "#     return photographers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'nabirds/'\n",
    "image_path  = 'nabirds/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = load_image_paths(dataset_path, path_prefix=image_path)\n",
    "image_sizes = load_image_sizes(dataset_path)\n",
    "# image_bboxes = load_bounding_box_annotations(dataset_path)\n",
    "# image_parts = load_part_annotations(dataset_path)\n",
    "image_class_labels = load_image_labels(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = load_class_names(dataset_path)\n",
    "class_hierarchy = load_hierarchy(dataset_path)\n",
    "\n",
    "# Load in the part data\n",
    "# part_names = load_part_names(dataset_path)\n",
    "# part_ids = part_names.keys()\n",
    "# part_ids = sorted(part_ids)\n",
    "\n",
    "# Load in the photographers\n",
    "# photographers = load_photographers(dataset_path)\n",
    "\n",
    "# Load in the train / test split\n",
    "train_images, test_images = load_train_test_split(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_paths['0090914b-db16-4b8f-9f95-045d8a90d09d']\n",
    "\n",
    "birds_filenames = [x for x in image_paths.values()]\n",
    "\n",
    "print(birds_filenames[0])\n",
    "print(len(birds_filenames))\n",
    "\n",
    "image = Image.open(birds_filenames[3000])\n",
    "print(np.array(image).shape)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20,10))\n",
    "\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('original')\n",
    "for ax, channel, name in zip(axes[1:], image.split(), ['red channel', 'green channel', 'blue channel']):\n",
    "    ax.imshow(channel, cmap='gray')\n",
    "    ax.set_title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
