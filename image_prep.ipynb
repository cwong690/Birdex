{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "import boto3\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "getattr(tqdm, '_instances', {}).clear()  # ⬅ add this line\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle # save images\n",
    "import time # get time stamp of models trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import text files (image names, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg # show images\n",
    "from io import BytesIO # reading bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe with images.txt\n",
    "\n",
    "_Contains name of images and file path_  \n",
    "- Split into file path, image name, and folder number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'cwbirdsimages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "img_txt = s3.get_object(Bucket=bucket, Key='images.txt')\n",
    "\n",
    "img_names = BytesIO(img_txt['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = pd.read_csv(img_names, header=None, low_memory=False, na_values='n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data['file_path'] = img_data[0].apply(lambda x: x.split()[1])\n",
    "img_data['img_name'] = img_data[0].apply(lambda x: x.split()[0])\n",
    "\n",
    "img_data['class_id'] = img_data['file_path'].apply(lambda x: x.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data.drop(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48562 entries, 0 to 48561\n",
      "Data columns (total 3 columns):\n",
      "file_path    48562 non-null object\n",
      "img_name     48562 non-null object\n",
      "class_id     48562 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "img_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'class_id' should be int\n",
    "img_data['class_id'] = img_data['class_id'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe of image_class_labels.txt\n",
    "\n",
    "_Contains name of image file and corresponding folder number_  \n",
    "- Split into image name, and folder number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "img_class = s3.get_object(Bucket=bucket, Key='image_class_labels.txt')\n",
    "\n",
    "img_class_labels = BytesIO(img_class['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(img_class_labels, header=None, low_memory=False, na_values='n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df['img_name'] = labels_df[0].apply(lambda x: x.split()[0])\n",
    "labels_df['class_id'] = labels_df[0].apply(lambda x: x.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.drop(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'class_id' should be int\n",
    "labels_df['class_id'] = labels_df['class_id'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48562 entries, 0 to 48561\n",
      "Data columns (total 2 columns):\n",
      "img_name    48562 non-null object\n",
      "class_id    48562 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 758.9+ KB\n"
     ]
    }
   ],
   "source": [
    "labels_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe with hierarchy.txt\n",
    "\n",
    "_Contains folder number and class number_  \n",
    "- Split into folder number and class number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# s3 = boto3.client('s3')\n",
    "# hierarchy_txt = s3.get_object(Bucket=bucket, Key='hierarchy.txt')\n",
    "\n",
    "# hierarchy = BytesIO(hierarchy_txt['Body'].read())\n",
    "\n",
    "# hier_df = pd.read_csv(hierarchy, header=None, low_memory=False, na_values='n/a')\n",
    "\n",
    "# hier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# hier_df['folder_num'] = hier_df[0].apply(lambda x: x.split()[0])\n",
    "# hier_df['class_id'] = hier_df[0].apply(lambda x: x.split()[1])\n",
    "\n",
    "# hier_df.drop(0, axis=1, inplace=True)\n",
    "\n",
    "# hier_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe with classes.txt\n",
    "\n",
    "_Contains class number and class labels_  \n",
    "- Split into class number and class labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "classes_txt = s3.get_object(Bucket=bucket, Key='classes.txt')\n",
    "\n",
    "classes = BytesIO(classes_txt['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df = pd.read_csv(classes, sep='\\t', header=None, low_memory=False, na_values='n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0 Birds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 Ducks, Geese, and Swans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2 Grouse, Quail, and Allies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3 Loons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 Grebes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "0                      0 Birds\n",
       "1    1 Ducks, Geese, and Swans\n",
       "2  2 Grouse, Quail, and Allies\n",
       "3                      3 Loons\n",
       "4                     4 Grebes"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df['class_id'] = classes_df[0].apply(lambda x: x.split(' ', 1)[0])\n",
    "classes_df['txt_labels'] = classes_df[0].apply(lambda x: x.split(' ', 1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_df.drop(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'class_id' should be int\n",
    "classes_df['class_id'] = classes_df['class_id'].apply(lambda x: int(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge all dataframes\n",
    "\n",
    "The folder numbers corresponds to the class ids\n",
    "merge the **img_data** dataframe (containing file path, image name, and class id) and the **classes_df** dataframe (class id and txt_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = img_data.merge(classes_df, on='class_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>img_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>txt_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [file_path, img_name, class_id, txt_labels]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df[master_df['class_id']==565]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48562, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 48562 entries, 0 to 48561\n",
      "Data columns (total 4 columns):\n",
      "file_path     48562 non-null object\n",
      "img_name      48562 non-null object\n",
      "class_id      48562 non-null int64\n",
      "txt_labels    48562 non-null object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "master_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>img_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>txt_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0817/0000139e21dc4d0cbfe14cae3c85c829.jpg</td>\n",
       "      <td>0000139e-21dc-4d0c-bfe1-4cae3c85c829</td>\n",
       "      <td>817</td>\n",
       "      <td>Oak Titmouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0817/01a472d8e93047a080aae4f958a2ef47.jpg</td>\n",
       "      <td>01a472d8-e930-47a0-80aa-e4f958a2ef47</td>\n",
       "      <td>817</td>\n",
       "      <td>Oak Titmouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0817/036fba7c96374635853511ead2c1c728.jpg</td>\n",
       "      <td>036fba7c-9637-4635-8535-11ead2c1c728</td>\n",
       "      <td>817</td>\n",
       "      <td>Oak Titmouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0817/07814887f59b44cb9b7f399999634fba.jpg</td>\n",
       "      <td>07814887-f59b-44cb-9b7f-399999634fba</td>\n",
       "      <td>817</td>\n",
       "      <td>Oak Titmouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0817/0822865741de43128a6a6c8897387975.jpg</td>\n",
       "      <td>08228657-41de-4312-8a6a-6c8897387975</td>\n",
       "      <td>817</td>\n",
       "      <td>Oak Titmouse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   file_path  \\\n",
       "0  0817/0000139e21dc4d0cbfe14cae3c85c829.jpg   \n",
       "1  0817/01a472d8e93047a080aae4f958a2ef47.jpg   \n",
       "2  0817/036fba7c96374635853511ead2c1c728.jpg   \n",
       "3  0817/07814887f59b44cb9b7f399999634fba.jpg   \n",
       "4  0817/0822865741de43128a6a6c8897387975.jpg   \n",
       "\n",
       "                               img_name  class_id    txt_labels  \n",
       "0  0000139e-21dc-4d0c-bfe1-4cae3c85c829       817  Oak Titmouse  \n",
       "1  01a472d8-e930-47a0-80aa-e4f958a2ef47       817  Oak Titmouse  \n",
       "2  036fba7c-9637-4635-8535-11ead2c1c728       817  Oak Titmouse  \n",
       "3  07814887-f59b-44cb-9b7f-399999634fba       817  Oak Titmouse  \n",
       "4  08228657-41de-4312-8a6a-6c8897387975       817  Oak Titmouse  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "master_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# master_df.to_csv('data/master_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df['txt_labels'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "555"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df['class_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48562"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(master_df['file_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47049    0982/ff17652d470c4730b57a5133d6b7d0cc.jpg\n",
       "Name: file_path, dtype: object"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df['file_path'][47049:47050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab and resize image from and to s3 bucket\n",
    "\n",
    "img_dir = 'images' # folder containing all other folders of images\n",
    "paths = master_df['file_path']\n",
    "\n",
    "def resize_images_array(img_dir, file_paths):\n",
    "    # arrays of image pixels\n",
    "    img_arrays = []\n",
    "    \n",
    "    paths = []\n",
    "    \n",
    "    # loop through the dataframe that is linked to its label so that all images are in the same order\n",
    "    for path in tqdm(file_paths):\n",
    "        s3 = boto3.client('s3')\n",
    "        try:\n",
    "            obj = s3.get_object(Bucket=bucket, Key=f'{img_dir}/{path}')\n",
    "            img_bytes = BytesIO(obj['Body'].read())\n",
    "            open_img = Image.open(img_bytes)\n",
    "            arr = np.array(open_img.resize((299,299))) # resize to 200,200. possible to play around with better or worse resolution\n",
    "            img_arrays.append(arr)\n",
    "            paths.append(path)\n",
    "        except:\n",
    "#             print(path) # get file_path of ones that fail to load\n",
    "            continue\n",
    "    return np.array(img_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# s3 = boto3.client('s3')\n",
    "# obj = s3.get_object(Bucket=bucket, Key=f'images/0817/0000139e21dc4d0cbfe14cae3c85c829.jpg')\n",
    "# img_bytes = BytesIO(obj['Body'].read())\n",
    "# open_img = Image.open(img_bytes)\n",
    "# arr = np.array(open_img.resize((200,200))) # resize to 200,200. possible to play around with better or worse resolution\n",
    "# s3.upload_file(arr, 'cwbirdsimages', 'resized_images/0817/0000139e21dc4d0cbfe14cae3c85c829.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### final data grab amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 40459/47001 [1:18:45<13:16,  8.22it/s]  "
     ]
    }
   ],
   "source": [
    "X = resize_images_array(img_dir, master_df['file_path'][:47001])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### small sample len and shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sm_samp = resize_images_array(img_dir, master_df['file_path'][:3098])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('length of sample: ', len(X))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the 3 channels of colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "single_img = master_df['file_path'][985]\n",
    "single_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "obj = s3.get_object(Bucket=bucket, Key=f'images/0776/16398b734cf540e3b0bcc943621e3515.jpg')\n",
    "img_bytes = BytesIO(obj['Body'].read())\n",
    "open_img = Image.open(img_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# By stacking these together into a 3-tensor, we can represent a color image as a single object.\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16,6))\n",
    "\n",
    "axes[0].imshow(open_img)\n",
    "axes[0].set_title('original')\n",
    "for ax, channel, name in zip(axes[1:], open_img.split(), ['red channel', 'green channel', 'blue channel']):\n",
    "    ax.imshow(channel)\n",
    "    ax.set_title(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create labels and features arrays and normalize features arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### small sample normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the RBG values\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = X.copy()\n",
    "\n",
    "# from tensorflow.keras.utils import normalize\n",
    "\n",
    "# backup = pd.HDFStore('backup.h5')\n",
    "\n",
    "# backup['X'] = pd.Series(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DONT FORGET TO CHANGE RANGE HERE TOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab numeric label\n",
    "# VALUES MUST BE NP.ARRAYS\n",
    "\n",
    "label = np.array(master_df['class_id'][:47001].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### y labels need to be one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (label.reshape(-1,1) == master_df['class_id'][:47001].unique()).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('label shape: ', y.shape)\n",
    "print('features shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['class_id'][:47001].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[115]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# sample = np.array([x.flatten() for x in xs_samp])\n",
    "# sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# clf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(sample, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(\"Train model\")\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Predictions\")\n",
    "# predicted = clf.predict(X_test)\n",
    "\n",
    "# # there are too many labels\n",
    "\n",
    "# print(\"Accuracy: \", accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization # CNN\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard # graphical visual of loss and accuracy over the epochs of train and test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import datetime\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# check to make sure the bird images and labels are aligned\n",
    "# this is indeed a semipalmated sandpiper\n",
    "\n",
    "print(master_df.iloc[57, :]['txt_labels'])\n",
    "plt.imshow(X[57]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "1. X, and y defined\n",
    "- make sure they are arrays!!\n",
    "\n",
    "2. normalize X values by dividing by 255\n",
    "3. check images\n",
    "4. train test split\n",
    "5. make model Sequential()\n",
    "6. add input layer\n",
    "7. add multiple hidden layers\n",
    "8. ADD FLATTEN LAYER, MUST BE BEFORE OUTPUT\n",
    "9. add dense layer, which are fully connected layers\n",
    "10. add output dense layer, will be the amount of labels there are\n",
    "11. model.compile(loss = 'sparse_categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "12. model.fit(xtrain, ytrain, epochs) also has validation_split (out of sample) do about 0.1, batchsize: how many at a time, more data requires bigger (20-200 range)\n",
    "13. model.evaluate(xtest,ytest) returns val loss and val accuracy  \n",
    "\n",
    "14. model.save('name') saves the model\n",
    "- to load: new_model = tf.keras.models.load_model('name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[55]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRANSFER LEARNING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_xcept = os.path.join(\"logs/large_xception\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_xcept, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (299,299,3)\n",
    "model = Xception(weights='imagenet',\n",
    "                          include_top=True,\n",
    "                          input_shape=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def print_model_properties(model, indices = 0):\n",
    "#      for i, layer in enumerate(model.layers[indices:]):\n",
    "#         print(f\"Layer {i+indices} | Name: {layer.name} | Trainable: {layer.trainable}\")\n",
    "\n",
    "# print_model_properties(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_model(input_size, n_categories, weights = 'imagenet'):\n",
    "        # note that the \"top\" is not included in the weights below\n",
    "        base_model = Xception(weights=weights,\n",
    "                          include_top=False,\n",
    "                          input_shape=input_size)\n",
    "        \n",
    "        model = base_model.output\n",
    "        model = GlobalAveragePooling2D()(model)\n",
    "        predictions = Dense(n_categories, activation='softmax')(model)\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = create_transfer_model((299,299,3),555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_trainable_layers(model, trainable_index):\n",
    "    for layer in model.layers[:trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[trainable_index:]:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = change_trainable_layers(transfer_model, 132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_model_properties(transfer_model, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xception_final = transfer_model.fit(X, y, batch_size=1000, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.save('saved_models/large_xception.h5')\n",
    "# load_L_xception = tf.keras.models.load_model('saved_models/large_xception.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_test = transfer_model.fit(X_train, y_train, batch_size = 32, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Transfer Model1: Loss and Accuracy')\n",
    "# evaluate = transfer_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred1 = transfer_model.predict(X_test)\n",
    "\n",
    "y_true = y_test.copy()\n",
    "\n",
    "y_true = np.array([i.argmax() for i in y_true]).reshape(-1,1)\n",
    "\n",
    "y_predicted = (pred1 > 0.5).astype(float)\n",
    "\n",
    "y_predicted = np.array([i.argmax() for i in y_predicted]).reshape(-1,1)\n",
    "\n",
    "mat = confusion_matrix(y_true, y_predicted)\n",
    "\n",
    "plot_confusion_matrix(conf_mat=mat, figsize=(8,8), class_names=folders);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Flatten(input_shape=X_train[0].shape))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(y_train.shape[1], activation='softmax')) # have to have same amount as y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model 0: Baseline Model NN')\n",
    "print(f'Number of Training Images: {X_train.shape[0]}/{X_train.shape[0] + X_test.shape[0]}')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model 0: Baseline Model NN')\n",
    "print(f'Number of Training Images: {X_train.shape[0]}/{X_train.shape[0] + X_test.shape[0]}')\n",
    "history = model.fit(X_train, y_train, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Weak Model Prediction Check: ')\n",
    "print('True label of bird: ', y_train[0].argmax(),classes_df.loc[379][['class_id', 'txt_labels']].values)\n",
    "print('Predicted label of bird: ', pred[0].argmax(), classes_df.loc[458][['class_id', 'txt_labels']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.iloc[:20047, :]['class_id'].unique()[201]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN: Convolutional Neural Network Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "model1 = Sequential()\n",
    "\n",
    "# Convolution Layer\n",
    "model1.add(Conv2D(32, (3,3), activation='relu', input_shape=X_train[0].shape)) # scans with a (3,3) grid\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D(2,2)) # grid to pool together the first grid\n",
    "model1.add(Dropout(0.3))\n",
    "\n",
    "model1.add(Conv2D(64, (3,3), activation='relu')) # scans with a (3,3) grid\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D(2,2)) # grid to pool together the first grid\n",
    "model1.add(Dropout(0.3))\n",
    "\n",
    "model1.add(Conv2D(128, (3,3), activation='relu')) # scans with a (3,3) grid\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPool2D(2,2)) # grid to pool together the first grid\n",
    "model1.add(Dropout(0.4))\n",
    "\n",
    "# Must Flatten before entering Dense layers\n",
    "model1.add(Flatten())\n",
    "\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dropout(0.4))\n",
    "\n",
    "model1.add(Dense(128, activation='relu'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(Dropout(0.4))\n",
    "\n",
    "model1.add(Dense(y_train.shape[1], activation='softmax')) # have to have same amount as y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model 1: CNN')\n",
    "print(f'Number of Training Images: {X_train.shape[0]}/{X_train.shape[0] + X_test.shape[0]}')\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\"logs/fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Model 1: CNN')\n",
    "print(f'Number of Training Images: {X_train.shape[0]}/{X_train.shape[0] + X_test.shape[0]}')\n",
    "history1 = model1.fit(X_train, y_train, batch_size = 100, epochs=10, validation_split=0.1, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(12,6))\n",
    "\n",
    "epoch_range = range(1, 11)\n",
    "\n",
    "axes[0].plot(epoch_range, history1.history['accuracy'])\n",
    "axes[0].plot(epoch_range, history1.history['val_accuracy'])\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_xlabel('Number of Epochs')\n",
    "axes[0].legend(['Train', 'Val'], loc='upper left')\n",
    "axes[0].set_title('Model2 Accuracy')\n",
    "\n",
    "axes[1].plot(epoch_range, history1.history['loss'])\n",
    "axes[1].plot(epoch_range, history1.history['val_loss'])\n",
    "axes[1].set_ylabel('Accuracy')\n",
    "axes[1].set_xlabel('Number of Epochs')\n",
    "axes[1].legend(['Train', 'Val'], loc='upper left')\n",
    "axes[1].set_title('Model2 Loss')\n",
    "\n",
    "plt.savefig('graphs/model2_acc_loss.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "\n",
    "# %tensorboard --logdir='logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('CNN Model 1 Prediction Check: ')\n",
    "print('True label of bird: ', classes_df[classes_df['class_id'] == master_df.iloc[:y.shape[0], :]['class_id'].unique()[y_test[0].argmax()]].values)\n",
    "print('Predicted label of bird: ', classes_df[classes_df['class_id'] == master_df.iloc[:y.shape[0], :]['class_id'].unique()[pred1[0].argmax()]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save('saved_models/conv-3-dense-2-fr32-128.h5')\n",
    "# keras.models.load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
