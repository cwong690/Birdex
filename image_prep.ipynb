{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import random\n",
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "import boto3\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Visualize the images and their annotations\n",
    "# image_identifiers = list(image_paths.keys())\n",
    "# random.shuffle(image_identifiers) \n",
    "# for image_id in image_identifiers:\n",
    "#     image_path = image_paths[image_id]\n",
    "#     image = plt.imread(image_path)\n",
    "#     bbox = image_bboxes[image_id]\n",
    "#     parts = image_parts[image_id]\n",
    "#     class_label = image_class_labels[image_id]\n",
    "#     class_name = class_names[class_label]\n",
    "      \n",
    "#     # Render the image\n",
    "#     plt.close(1)\n",
    "#     fig = plt.figure(1, figsize=(16, 12))\n",
    "#     plt.imshow(image)\n",
    "#     plt.title(\"Image ID: %s \\n Class Label: %s  [ID: %s]\" % (image_id, class_name, class_label))\n",
    "      \n",
    "#     # Render the bounding box annotations\n",
    "#     bbox_x, bbox_y, bbox_width, bbox_height = bbox\n",
    "#     currentAxis = plt.gca()\n",
    "#     currentAxis.add_patch(plt.Rectangle((bbox_x , bbox_y), bbox_width, bbox_height, facecolor=\"green\", alpha=0.3))\n",
    "      \n",
    "#     # Render the part annotations\n",
    "#     if has_networkx:\n",
    "#     # Use networkx spring layout\n",
    "        \n",
    "#         G = nx.Graph()\n",
    "#         part_data = []\n",
    "#         initial_positions = {}\n",
    "#         for part_id, part in enumerate(parts):\n",
    "#             x, y, v = part\n",
    "#             if v:\n",
    "#                 part_str = 'part_%d' % (part_id,)\n",
    "#                 label_str = 'label_%d' % (part_id,)\n",
    "            \n",
    "#                 G.add_node(part_str)\n",
    "#                 G.add_node(label_str)\n",
    "#                 G.add_edge(part_str, label_str)\n",
    "            \n",
    "#                 part_data.append(part_str)\n",
    "            \n",
    "#                 initial_positions[part_str] = (x, y)\n",
    "#                 initial_positions[label_str] = (x, y)\n",
    "            \n",
    "#             positions = nx.spring_layout(G, dim=2, k=20.0, pos=initial_positions, fixed=part_data)\n",
    "        \n",
    "#             for part_id, part in enumerate(parts):\n",
    "#                 x, y, v = part\n",
    "#                 if v:\n",
    "#                     plt.plot(x, y, 'o')\n",
    "            \n",
    "#                     label_str = 'label_%d' % (part_id,)\n",
    "#                     label_position = positions[label_str]\n",
    "#                     label_xy = (label_position[0] * bbox_width + bbox_x, label_position[1] * bbox_height + bbox_y)\n",
    "#                     plt.annotate(\n",
    "#                       part_names[part_id], \n",
    "#                       xy=(x, y),\n",
    "#                       xycoords='data', \n",
    "#                       xytext= label_xy, \n",
    "#                       textcoords='data',\n",
    "#                       ha='right', \n",
    "#                       va='bottom',\n",
    "#                       bbox=dict(boxstyle= 'round,pad=0.5', \n",
    "#                             fc='yellow', \n",
    "#                             alpha=0.5),\n",
    "#                       arrowprops=dict(arrowstyle='->', \n",
    "#                               connectionstyle='arc3,rad=0')\n",
    "#                     )\n",
    "    \n",
    "#                 else:\n",
    "#                     # just a basic label annotation for the part locations\n",
    "#                     offset = (2 * math.pi) / len(parts)\n",
    "#                     for part_id, part in enumerate(parts):\n",
    "#                         x, y, v = part\n",
    "#                         if v: \n",
    "#                             # try to offset the part labels so that they don't overlap too badly\n",
    "#                             dist = random.randint(35, 65)\n",
    "#                             offset_x = dist * math.cos(offset * part_id)\n",
    "#                             offset_y = dist * math.sin(offset * part_id)\n",
    "          \n",
    "#                             plt.plot(x, y, 'o')\n",
    "#                             plt.annotate(\n",
    "#                               part_names[part_id], \n",
    "#                               xy=(x, y), \n",
    "#                               xytext=(offset_x, offset_y), \n",
    "#                               textcoords='offset points', \n",
    "#                               ha='right', \n",
    "#                               va='bottom',\n",
    "#                               bbox=dict(boxstyle= 'round,pad=0.5', \n",
    "#                                 fc='yellow', \n",
    "#                                 alpha=0.5),\n",
    "#                               arrowprops=dict(arrowstyle='->', \n",
    "#                                   connectionstyle='arc3,rad=0')\n",
    "#                             )\n",
    "  \n",
    "#     plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def rename_multiple_files(path,obj):\n",
    "\n",
    "#     i=0\n",
    "\n",
    "#     for filename in os.listdir(path):\n",
    "#         try:\n",
    "#             f,extension = os.path.splitext(path+filename)\n",
    "#             src=path+'/'+filename\n",
    "#             dst=path+'/'+obj+str(i)+extension\n",
    "#             os.rename(src,dst)\n",
    "#             i+=1\n",
    "#             print('Rename successful.')\n",
    "#         except:\n",
    "#             i+=1\n",
    "\n",
    "# path='training_set'\n",
    "# obj=f\"{src_path.split('.')[1]}\"\n",
    "# rename_multiple_files(path,obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras and tensorflow downloads\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D # CNN\n",
    "from tensorflow.keras.callbacks import TensorBoard # graphical visual of loss and accuracy over the epochs of train and test set\n",
    "\n",
    "import pickle # save images\n",
    "import time # get time stamp of models trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import text files (image names, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg # show images\n",
    "from io import BytesIO # reading bytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe with images.txt\n",
    "\n",
    "_Contains name of images and file path_  \n",
    "- Split into file path, image name, and folder number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'cwbirdsimages'\n",
    "img_dir = 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "img_txt = s3.get_object(Bucket=bucket, Key='images.txt')\n",
    "\n",
    "img_names = BytesIO(img_txt['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(img_names, header=None, low_memory=False, na_values='n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['file_path'] = data[0].apply(lambda x: x.split()[1])\n",
    "data['img_name'] = data[0].apply(lambda x: x.split()[0])\n",
    "\n",
    "data['folder_num'] = data['file_path'].apply(lambda x: x.split('/')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>img_name</th>\n",
       "      <th>folder_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0817/0000139e21dc4d0cbfe14cae3c85c829.jpg</td>\n",
       "      <td>0000139e-21dc-4d0c-bfe1-4cae3c85c829</td>\n",
       "      <td>0817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0860/0000d9fc4e024c06a0afa55cfb16b12b.jpg</td>\n",
       "      <td>0000d9fc-4e02-4c06-a0af-a55cfb16b12b</td>\n",
       "      <td>0860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0900/000193069d834334b255a447742edce3.jpg</td>\n",
       "      <td>00019306-9d83-4334-b255-a447742edce3</td>\n",
       "      <td>0900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0645/0001afd499a14a67b940d419413e23b3.jpg</td>\n",
       "      <td>0001afd4-99a1-4a67-b940-d419413e23b3</td>\n",
       "      <td>0645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0929/000332b8997c454096472f0a8495aecf.jpg</td>\n",
       "      <td>000332b8-997c-4540-9647-2f0a8495aecf</td>\n",
       "      <td>0929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48557</th>\n",
       "      <td>0891/fff86e8b795f400a91e8565bbb8c453a.jpg</td>\n",
       "      <td>fff86e8b-795f-400a-91e8-565bbb8c453a</td>\n",
       "      <td>0891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48558</th>\n",
       "      <td>0660/fff926d7ccad4788839e97af2dd99372.jpg</td>\n",
       "      <td>fff926d7-ccad-4788-839e-97af2dd99372</td>\n",
       "      <td>0660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48559</th>\n",
       "      <td>0492/fffa33efa765408d8d666efc7f504c71.jpg</td>\n",
       "      <td>fffa33ef-a765-408d-8d66-6efc7f504c71</td>\n",
       "      <td>0492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48560</th>\n",
       "      <td>0372/ffff0d87bc844ef2a47ea4bfa48502ce.jpg</td>\n",
       "      <td>ffff0d87-bc84-4ef2-a47e-a4bfa48502ce</td>\n",
       "      <td>0372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48561</th>\n",
       "      <td>0880/fffff3a52a7547d0887f03871e3f9a37.jpg</td>\n",
       "      <td>fffff3a5-2a75-47d0-887f-03871e3f9a37</td>\n",
       "      <td>0880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48562 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file_path  \\\n",
       "0      0817/0000139e21dc4d0cbfe14cae3c85c829.jpg   \n",
       "1      0860/0000d9fc4e024c06a0afa55cfb16b12b.jpg   \n",
       "2      0900/000193069d834334b255a447742edce3.jpg   \n",
       "3      0645/0001afd499a14a67b940d419413e23b3.jpg   \n",
       "4      0929/000332b8997c454096472f0a8495aecf.jpg   \n",
       "...                                          ...   \n",
       "48557  0891/fff86e8b795f400a91e8565bbb8c453a.jpg   \n",
       "48558  0660/fff926d7ccad4788839e97af2dd99372.jpg   \n",
       "48559  0492/fffa33efa765408d8d666efc7f504c71.jpg   \n",
       "48560  0372/ffff0d87bc844ef2a47ea4bfa48502ce.jpg   \n",
       "48561  0880/fffff3a52a7547d0887f03871e3f9a37.jpg   \n",
       "\n",
       "                                   img_name folder_num  \n",
       "0      0000139e-21dc-4d0c-bfe1-4cae3c85c829       0817  \n",
       "1      0000d9fc-4e02-4c06-a0af-a55cfb16b12b       0860  \n",
       "2      00019306-9d83-4334-b255-a447742edce3       0900  \n",
       "3      0001afd4-99a1-4a67-b940-d419413e23b3       0645  \n",
       "4      000332b8-997c-4540-9647-2f0a8495aecf       0929  \n",
       "...                                     ...        ...  \n",
       "48557  fff86e8b-795f-400a-91e8-565bbb8c453a       0891  \n",
       "48558  fff926d7-ccad-4788-839e-97af2dd99372       0660  \n",
       "48559  fffa33ef-a765-408d-8d66-6efc7f504c71       0492  \n",
       "48560  ffff0d87-bc84-4ef2-a47e-a4bfa48502ce       0372  \n",
       "48561  fffff3a5-2a75-47d0-887f-03871e3f9a37       0880  \n",
       "\n",
       "[48562 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe of image_class_labels.txt\n",
    "\n",
    "_Contains name of image file and corresponding folder number_  \n",
    "- Split into image name, and folder number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "img_class = s3.get_object(Bucket=bucket, Key='image_class_labels.txt')\n",
    "\n",
    "img_class_labels = BytesIO(img_class['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(img_class_labels, header=None, low_memory=False, na_values='n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000139e-21dc-4d0c-bfe1-4cae3c85c829 817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000d9fc-4e02-4c06-a0af-a55cfb16b12b 860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00019306-9d83-4334-b255-a447742edce3 900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001afd4-99a1-4a67-b940-d419413e23b3 645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000332b8-997c-4540-9647-2f0a8495aecf 929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48557</th>\n",
       "      <td>fff86e8b-795f-400a-91e8-565bbb8c453a 891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48558</th>\n",
       "      <td>fff926d7-ccad-4788-839e-97af2dd99372 660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48559</th>\n",
       "      <td>fffa33ef-a765-408d-8d66-6efc7f504c71 492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48560</th>\n",
       "      <td>ffff0d87-bc84-4ef2-a47e-a4bfa48502ce 372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48561</th>\n",
       "      <td>fffff3a5-2a75-47d0-887f-03871e3f9a37 880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48562 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              0\n",
       "0      0000139e-21dc-4d0c-bfe1-4cae3c85c829 817\n",
       "1      0000d9fc-4e02-4c06-a0af-a55cfb16b12b 860\n",
       "2      00019306-9d83-4334-b255-a447742edce3 900\n",
       "3      0001afd4-99a1-4a67-b940-d419413e23b3 645\n",
       "4      000332b8-997c-4540-9647-2f0a8495aecf 929\n",
       "...                                         ...\n",
       "48557  fff86e8b-795f-400a-91e8-565bbb8c453a 891\n",
       "48558  fff926d7-ccad-4788-839e-97af2dd99372 660\n",
       "48559  fffa33ef-a765-408d-8d66-6efc7f504c71 492\n",
       "48560  ffff0d87-bc84-4ef2-a47e-a4bfa48502ce 372\n",
       "48561  fffff3a5-2a75-47d0-887f-03871e3f9a37 880\n",
       "\n",
       "[48562 rows x 1 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df['img_name'] = labels_df[0].apply(lambda x: x.split()[0])\n",
    "labels_df['folder_num'] = labels_df[0].apply(lambda x: x.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df.drop(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>folder_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000139e-21dc-4d0c-bfe1-4cae3c85c829</td>\n",
       "      <td>817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000d9fc-4e02-4c06-a0af-a55cfb16b12b</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00019306-9d83-4334-b255-a447742edce3</td>\n",
       "      <td>900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001afd4-99a1-4a67-b940-d419413e23b3</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000332b8-997c-4540-9647-2f0a8495aecf</td>\n",
       "      <td>929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48557</th>\n",
       "      <td>fff86e8b-795f-400a-91e8-565bbb8c453a</td>\n",
       "      <td>891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48558</th>\n",
       "      <td>fff926d7-ccad-4788-839e-97af2dd99372</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48559</th>\n",
       "      <td>fffa33ef-a765-408d-8d66-6efc7f504c71</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48560</th>\n",
       "      <td>ffff0d87-bc84-4ef2-a47e-a4bfa48502ce</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48561</th>\n",
       "      <td>fffff3a5-2a75-47d0-887f-03871e3f9a37</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48562 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   img_name folder_num\n",
       "0      0000139e-21dc-4d0c-bfe1-4cae3c85c829        817\n",
       "1      0000d9fc-4e02-4c06-a0af-a55cfb16b12b        860\n",
       "2      00019306-9d83-4334-b255-a447742edce3        900\n",
       "3      0001afd4-99a1-4a67-b940-d419413e23b3        645\n",
       "4      000332b8-997c-4540-9647-2f0a8495aecf        929\n",
       "...                                     ...        ...\n",
       "48557  fff86e8b-795f-400a-91e8-565bbb8c453a        891\n",
       "48558  fff926d7-ccad-4788-839e-97af2dd99372        660\n",
       "48559  fffa33ef-a765-408d-8d66-6efc7f504c71        492\n",
       "48560  ffff0d87-bc84-4ef2-a47e-a4bfa48502ce        372\n",
       "48561  fffff3a5-2a75-47d0-887f-03871e3f9a37        880\n",
       "\n",
       "[48562 rows x 2 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe with hierarchy.txt\n",
    "\n",
    "_Contains folder number and class number_  \n",
    "- Split into folder number and class number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "hierarchy_txt = s3.get_object(Bucket=bucket, Key='hierarchy.txt')\n",
    "\n",
    "hierarchy = BytesIO(hierarchy_txt['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_df = pd.read_csv(hierarchy, header=None, low_memory=False, na_values='n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1 0\n",
       "1  2 0\n",
       "2  3 0\n",
       "3  4 0\n",
       "4  5 0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hier_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_df['folder_num'] = hier_df[0].apply(lambda x: x.split()[0])\n",
    "hier_df['class_num'] = hier_df[0].apply(lambda x: x.split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_df.drop(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder_num</th>\n",
       "      <th>class_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>1006</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>1007</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>1008</td>\n",
       "      <td>704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>1009</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>1010</td>\n",
       "      <td>744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     folder_num class_num\n",
       "0             1         0\n",
       "1             2         0\n",
       "2             3         0\n",
       "3             4         0\n",
       "4             5         0\n",
       "...         ...       ...\n",
       "1005       1006       591\n",
       "1006       1007       259\n",
       "1007       1008       704\n",
       "1008       1009       691\n",
       "1009       1010       744\n",
       "\n",
       "[1010 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hier_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe with classes.txt\n",
    "\n",
    "_Contains class number and class labels_  \n",
    "- Split into class number and class labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "classes_txt = s3.get_object(Bucket=bucket, Key='classes.txt')\n",
    "\n",
    "classes = BytesIO(classes_txt['Body'].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-d3c10461a49e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclasses_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'n/a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "classes_df = pd.read_csv(classes, header=None, low_memory=False, na_values='n/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "obj = s3.get_object(Bucket=bucket, Key=f'{img_path}/0295/01f53d6bf5e449438d2bb79e0854bca4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj['Body'].read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = BytesIO(obj['Body'].read())\n",
    "im = mpimg.imread(data, 'jpg')\n",
    "\n",
    "plt.figure(0)\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loan_data = []\n",
    "#     for filename in csv_files:\n",
    "#         s3 = boto3.client('s3')\n",
    "#         obj = s3.get_object(Bucket=bucket, Key=filename)\n",
    "#         data = obj['Body'].read()\n",
    "#         f = BytesIO(data)\n",
    "#         data = pd.read_csv(f, header=1, low_memory=False, na_values='n/a',\n",
    "#                            usecols=columns, nrows=number_of_rows) \n",
    "#         loan_data.append(data)\n",
    "#     loans = pd.concat(loan_data)\n",
    "#     # Loan IDs are unique and we can access specific loans much faster by setting them as the index.\n",
    "#     #loans.set_index('id', inplace=True)\n",
    "#     return loans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def resize_multiple_images(src_folder, dst_path):\n",
    "    # src_folder is the location where images are saved\n",
    "    for dirpath, dirnames, filenames in os.walk(src_folder):\n",
    "        for filename in os.listdir(dirpath):\n",
    "            try:\n",
    "                img=Image.open(filename+'.jpg')\n",
    "                new_img = img.resize((64,64))\n",
    "                if not os.path.exists(dst_path):\n",
    "                    os.makedirs(dst_path)\n",
    "                new_img.save(dst_path+'/'+filename)\n",
    "                print('Resized and saved {}.'.format(filename))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "# src_folder = 'images'\n",
    "# dst_path = 'resized_images'\n",
    "# resize_multiple_images(src_folder, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def get_data(path):\n",
    "    all_images_as_array=[]\n",
    "    label=[]\n",
    "    for filename in os.listdir(path):\n",
    "        try:\n",
    "            if re.match(r'Black_footed_Albatross',filename):\n",
    "                label.append(1)\n",
    "            else:\n",
    "                label.append(0)\n",
    "            img=Image.open(path + '/'+ filename)\n",
    "            np_array = np.asarray(img)\n",
    "            l,b,c = np_array.shape\n",
    "            np_array = np_array.reshape(l*b*c,)\n",
    "            all_images_as_array.append(np_array)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    return np.array(all_images_as_array), np.array(label)\n",
    "\n",
    "# path_to_train_set = 'train_set/'\n",
    "# path_to_test_set = 'test_set/'\n",
    "# X_train,y_train = get_data(path_to_train_set)\n",
    "# X_test, y_test = get_data(path_to_test_set)\n",
    "\n",
    "# print('X_train set : ',X_train)\n",
    "# print('y_train set : ',y_train)\n",
    "# print('X_test set : ',X_test)\n",
    "# print('y_test set : ',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def load_bounding_box_annotations(dataset_path=''):\n",
    "#     bboxes = {}\n",
    "#     with open(os.path.join(dataset_path, 'bounding_boxes.txt')) as f:\n",
    "#         for line in f:\n",
    "#             pieces = line.strip().split()\n",
    "#             image_id = pieces[0]\n",
    "#             bbox = map(int, pieces[1:])\n",
    "#             bboxes[image_id] = bbox\n",
    "#     return bboxes\n",
    "\n",
    "# def load_part_annotations(dataset_path=''):\n",
    "#     parts = {}\n",
    "#     with open(os.path.join(dataset_path, 'parts/part_locs.txt')) as f:\n",
    "#         for line in f:\n",
    "#             pieces = line.strip().split()\n",
    "#             image_id = pieces[0]\n",
    "#             parts.setdefault(image_id, [0] * 11)\n",
    "#             part_id = int(pieces[1])\n",
    "#             parts[image_id][part_id] = [int(x) for x in pieces[2:]]\n",
    "#     return parts  \n",
    "  \n",
    "# def load_part_names(dataset_path=''):\n",
    "#     names = {}\n",
    "#     with open(os.path.join(dataset_path, 'parts/parts.txt')) as f:\n",
    "#         for line in f:\n",
    "#             pieces = line.strip().split()\n",
    "#             part_id = int(pieces[0])\n",
    "#             names[part_id] = ' '.join(pieces[1:])\n",
    "#     return names  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_class_names(dataset_path=''):\n",
    "    names = {}\n",
    "    with open(os.path.join(dataset_path, 'classes.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            class_id = pieces[0]\n",
    "            names[class_id] = ' '.join(pieces[1:])\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_labels(dataset_path=''):\n",
    "    labels = {}\n",
    "    with open(os.path.join(dataset_path, 'image_class_labels.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            image_id = pieces[0]\n",
    "            class_id = pieces[1]\n",
    "            labels[image_id] = class_id\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def load_image_paths(dataset_path='', path_prefix=''):\n",
    "    paths = {}\n",
    "    with open(os.path.join(dataset_path, 'images.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            image_id = pieces[0]\n",
    "            path = os.path.join(path_prefix, pieces[1])\n",
    "            paths[image_id] = path\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_sizes(dataset_path=''):\n",
    "    sizes = {}\n",
    "    with open(os.path.join(dataset_path, 'sizes.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            image_id = pieces[0]\n",
    "            width, height = map(int, pieces[1:])\n",
    "            sizes[image_id] = [width, height]\n",
    "    return sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_hierarchy(dataset_path=''):\n",
    "    parents = {}\n",
    "    with open(os.path.join(dataset_path, 'hierarchy.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            child_id, parent_id = pieces\n",
    "            parents[child_id] = parent_id\n",
    "    return parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_split(dataset_path=''):\n",
    "    train_images = []\n",
    "    test_images = []\n",
    "    with open(os.path.join(dataset_path, 'train_test_split.txt')) as f:\n",
    "        for line in f:\n",
    "            pieces = line.strip().split()\n",
    "            image_id = pieces[0]\n",
    "            is_train = int(pieces[1])\n",
    "            if is_train:\n",
    "                train_images.append(image_id)\n",
    "            else:\n",
    "                test_images.append(image_id)\n",
    "    return train_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# def load_photographers(dataset_path=''):\n",
    "#     photographers = {}\n",
    "#     with open(os.path.join(dataset_path, 'photographers.txt')) as f:\n",
    "#         for line in f:\n",
    "#             pieces = line.strip().split()\n",
    "#             image_id = pieces[0]\n",
    "#             photographers[image_id] = ' '.join(pieces[1:])\n",
    "#     return photographers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = 'nabirds/'\n",
    "image_path  = 'nabirds/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = load_image_paths(dataset_path, path_prefix=image_path)\n",
    "image_sizes = load_image_sizes(dataset_path)\n",
    "# image_bboxes = load_bounding_box_annotations(dataset_path)\n",
    "# image_parts = load_part_annotations(dataset_path)\n",
    "image_class_labels = load_image_labels(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = load_class_names(dataset_path)\n",
    "class_hierarchy = load_hierarchy(dataset_path)\n",
    "\n",
    "# Load in the part data\n",
    "# part_names = load_part_names(dataset_path)\n",
    "# part_ids = part_names.keys()\n",
    "# part_ids = sorted(part_ids)\n",
    "\n",
    "# Load in the photographers\n",
    "# photographers = load_photographers(dataset_path)\n",
    "\n",
    "# Load in the train / test split\n",
    "train_images, test_images = load_train_test_split(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_paths['0090914b-db16-4b8f-9f95-045d8a90d09d']\n",
    "\n",
    "birds_filenames = [x for x in image_paths.values()]\n",
    "\n",
    "print(birds_filenames[0])\n",
    "print(len(birds_filenames))\n",
    "\n",
    "image = Image.open(birds_filenames[3000])\n",
    "print(np.array(image).shape)\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(20,10))\n",
    "\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title('original')\n",
    "for ax, channel, name in zip(axes[1:], image.split(), ['red channel', 'green channel', 'blue channel']):\n",
    "    ax.imshow(channel, cmap='gray')\n",
    "    ax.set_title(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
