{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import random\n",
    "import math\n",
    "import networkx as nx\n",
    "\n",
    "import boto3\n",
    "from PIL import Image\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "getattr(tqdm, '_instances', {}).clear()  # ⬅ add this line\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg # show images\n",
    "from io import BytesIO # reading bytes\n",
    "\n",
    "import pickle # save images\n",
    "import time # get time stamp of models trained\n",
    "import shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab and resize image from and to s3 bucket\n",
    "\n",
    "bucket = 'cwbirdsimages'\n",
    "img_dir = 'new_images' # folder containing all other folders of images\n",
    "folders = ['ducks', 'finches', 'hawks']\n",
    "\n",
    "def resize_images_array(img_dir, folders, bucket):\n",
    "    # arrays of image pixels\n",
    "    img_arrays = []\n",
    "    labels = []\n",
    "    \n",
    "    # loop through the dataframe that is linked to its label so that all images are in the same order\n",
    "    for folder in tqdm(folders):\n",
    "        s3 = boto3.client('s3')\n",
    "        enter_folder = s3.list_objects_v2(Bucket=bucket, Prefix=f'{img_dir}/{folder}')\n",
    "        for i in enter_folder['Contents'][2:]:\n",
    "            try:\n",
    "                filepath = i['Key']\n",
    "                obj = s3.get_object(Bucket=bucket, Key=f'{filepath}')\n",
    "                img_bytes = BytesIO(obj['Body'].read())\n",
    "                open_img = Image.open(img_bytes)\n",
    "                arr = np.array(open_img.resize((299,299))) # resize to 200,200. possible to play around with better or worse resolution\n",
    "                img_arrays.append(arr)\n",
    "                labels.append(folder)\n",
    "            except:\n",
    "                print(filepath) # get file_path of ones that fail to load\n",
    "                continue\n",
    "\n",
    "    return np.array(img_arrays), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [04:34<00:00, 91.55s/it]\n"
     ]
    }
   ],
   "source": [
    "X, y = resize_images_array(img_dir, folders, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:  (2986, 299, 299, 3)\n",
      "y_shape:  (2986,)\n"
     ]
    }
   ],
   "source": [
    "print('X shape: ', X.shape)\n",
    "print('y_shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img_df = pd.DataFrame(y)\n",
    "\n",
    "# img_df['img_array'] = [i.flatten() for i in X]\n",
    "\n",
    "# img_df.info()\n",
    "\n",
    "# img_df.to_csv('data/img_df.csv')\n",
    "\n",
    "# imgs = pd.read_csv('data/img_df.csv', index_col=0)\n",
    "\n",
    "# X = [np.array(i).reshape(299,299,3) for i in imgs['img_array']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client('s3')\n",
    "\n",
    "# grab duck image\n",
    "obj = s3.get_object(Bucket=bucket, Key=f'new_images/ducks/0296/069519c379574fb285d7bb920443ea89.jpg')\n",
    "img_bytes = BytesIO(obj['Body'].read())\n",
    "duck1 = Image.open(img_bytes)\n",
    "\n",
    "# grab hawk image\n",
    "obj = s3.get_object(Bucket=bucket, Key=f'new_images/hawks/0495/03126240f9974b259e1c0bc142af7edc.jpg')\n",
    "img_bytes = BytesIO(obj['Body'].read())\n",
    "hawk1 = Image.open(img_bytes)\n",
    "\n",
    "# grab finch image\n",
    "obj = s3.get_object(Bucket=bucket, Key=f'new_images/finches/1001/0edd165e46054dd388dcb9dae4e58f87.jpg')\n",
    "img_bytes = BytesIO(obj['Body'].read())\n",
    "finch1 = Image.open(img_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By stacking these together into a 3-tensor, we can represent a color image as a single object.\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20,10));\n",
    "\n",
    "fig.suptitle('RBG Channels of Images', y=1.1, fontsize=20)\n",
    "\n",
    "axes[0][0].imshow(duck1);\n",
    "axes[0][0].set_title('original')\n",
    "for ax, channel, name in zip(axes[0][1:], duck1.split(), ['red channel', 'green channel', 'blue channel']):\n",
    "    ax.imshow(channel, cmap=f'{name.split()[0].capitalize()}s_r');\n",
    "    ax.set_title(name)\n",
    "    \n",
    "axes[1][0].imshow(hawk1);\n",
    "axes[1][0].set_title('original')\n",
    "for ax, channel, name in zip(axes[1][1:], hawk1.split(), ['red channel', 'green channel', 'blue channel']):\n",
    "    ax.imshow(channel, cmap=f'{name.split()[0].capitalize()}s_r');\n",
    "    ax.set_title(name)\n",
    "    \n",
    "axes[2][0].imshow(finch1);\n",
    "axes[2][0].set_title('original')\n",
    "for ax, channel, name in zip(axes[2][1:], finch1.split(), ['red channel', 'green channel', 'blue channel']):\n",
    "    ax.imshow(channel, cmap=f'{name.split()[0].capitalize()}s_r');\n",
    "    ax.set_title(name)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graphs/dhf_RBGplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Feature Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the RBG values\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = y.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ducks', 'ducks', 'ducks', ..., 'hawks', 'hawks', 'hawks'],\n",
       "      dtype='<U7')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ducks:  990\n",
      "Number of Finches:  998\n",
      "Number of Hawks:  998\n"
     ]
    }
   ],
   "source": [
    "print('Number of Ducks: ', np.sum(label == 'ducks'))\n",
    "print('Number of Finches: ', np.sum(label == 'finches'))\n",
    "print('Number of Hawks: ', np.sum(label == 'hawks'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(label.reshape(-1,1) == folders).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label shape:  (2986, 3)\n",
      "features shape:  (2986, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print('label shape: ', y.shape)\n",
    "print('features shape: ', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Work Flow\n",
    "\n",
    "1. X, and y defined\n",
    "- make sure they are arrays!!\n",
    "\n",
    "2. normalize X values by dividing by 255\n",
    "3. check images\n",
    "4. train test split\n",
    "5. make model Sequential()\n",
    "6. add input layer\n",
    "7. add multiple hidden layers\n",
    "8. ADD FLATTEN LAYER, MUST BE BEFORE OUTPUT\n",
    "9. add dense layer, which are fully connected layers\n",
    "10. add output dense layer, will be the amount of labels there are\n",
    "11. model.compile(loss = 'sparse_categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
    "12. model.fit(xtrain, ytrain, epochs) also has validation_split (out of sample) do about 0.1, batchsize: how many at a time, more data requires bigger (20-200 range)\n",
    "13. model.evaluate(xtest,ytest) returns val loss and val accuracy  \n",
    "\n",
    "14. model.save('name') saves the model\n",
    "- to load: new_model = tf.keras.models.load_model('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keras and tensorflow downloads\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, BatchNormalization # CNN\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard # graphical visual of loss and accuracy over the epochs of train and test set\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlxtend\n",
    "\n",
    "import datetime\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to make sure the bird images and labels are aligned\n",
    "# this is indeed a duck\n",
    "\n",
    "plt.title(f'{folders[y_train[10].argmax()]}')\n",
    "plt.imshow(X_train[10]);\n",
    "\n",
    "# plt.savefig('graphs/duck1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('X_train shape: ', X_train.shape)\n",
    "print('X_test shape: ', X_test.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('y_test shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception: Transfer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_xcept = os.path.join(\"logs/xception\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(log_dir=log_xcept, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "\n",
    "# %tensorboard --logdir='logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (299,299,3)\n",
    "model = Xception(weights='imagenet',\n",
    "                          include_top=True,\n",
    "                          input_shape=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_properties(model, indices = 0):\n",
    "     for i, layer in enumerate(model.layers[indices:]):\n",
    "        print(f\"Layer {i+indices} | Name: {layer.name} | Trainable: {layer.trainable}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 0 | Name: input_1 | Trainable: True\n",
      "Layer 1 | Name: block1_conv1 | Trainable: True\n",
      "Layer 2 | Name: block1_conv1_bn | Trainable: True\n",
      "Layer 3 | Name: block1_conv1_act | Trainable: True\n",
      "Layer 4 | Name: block1_conv2 | Trainable: True\n",
      "Layer 5 | Name: block1_conv2_bn | Trainable: True\n",
      "Layer 6 | Name: block1_conv2_act | Trainable: True\n",
      "Layer 7 | Name: block2_sepconv1 | Trainable: True\n",
      "Layer 8 | Name: block2_sepconv1_bn | Trainable: True\n",
      "Layer 9 | Name: block2_sepconv2_act | Trainable: True\n",
      "Layer 10 | Name: block2_sepconv2 | Trainable: True\n",
      "Layer 11 | Name: block2_sepconv2_bn | Trainable: True\n",
      "Layer 12 | Name: conv2d | Trainable: True\n",
      "Layer 13 | Name: block2_pool | Trainable: True\n",
      "Layer 14 | Name: batch_normalization | Trainable: True\n",
      "Layer 15 | Name: add | Trainable: True\n",
      "Layer 16 | Name: block3_sepconv1_act | Trainable: True\n",
      "Layer 17 | Name: block3_sepconv1 | Trainable: True\n",
      "Layer 18 | Name: block3_sepconv1_bn | Trainable: True\n",
      "Layer 19 | Name: block3_sepconv2_act | Trainable: True\n",
      "Layer 20 | Name: block3_sepconv2 | Trainable: True\n",
      "Layer 21 | Name: block3_sepconv2_bn | Trainable: True\n",
      "Layer 22 | Name: conv2d_1 | Trainable: True\n",
      "Layer 23 | Name: block3_pool | Trainable: True\n",
      "Layer 24 | Name: batch_normalization_1 | Trainable: True\n",
      "Layer 25 | Name: add_1 | Trainable: True\n",
      "Layer 26 | Name: block4_sepconv1_act | Trainable: True\n",
      "Layer 27 | Name: block4_sepconv1 | Trainable: True\n",
      "Layer 28 | Name: block4_sepconv1_bn | Trainable: True\n",
      "Layer 29 | Name: block4_sepconv2_act | Trainable: True\n",
      "Layer 30 | Name: block4_sepconv2 | Trainable: True\n",
      "Layer 31 | Name: block4_sepconv2_bn | Trainable: True\n",
      "Layer 32 | Name: conv2d_2 | Trainable: True\n",
      "Layer 33 | Name: block4_pool | Trainable: True\n",
      "Layer 34 | Name: batch_normalization_2 | Trainable: True\n",
      "Layer 35 | Name: add_2 | Trainable: True\n",
      "Layer 36 | Name: block5_sepconv1_act | Trainable: True\n",
      "Layer 37 | Name: block5_sepconv1 | Trainable: True\n",
      "Layer 38 | Name: block5_sepconv1_bn | Trainable: True\n",
      "Layer 39 | Name: block5_sepconv2_act | Trainable: True\n",
      "Layer 40 | Name: block5_sepconv2 | Trainable: True\n",
      "Layer 41 | Name: block5_sepconv2_bn | Trainable: True\n",
      "Layer 42 | Name: block5_sepconv3_act | Trainable: True\n",
      "Layer 43 | Name: block5_sepconv3 | Trainable: True\n",
      "Layer 44 | Name: block5_sepconv3_bn | Trainable: True\n",
      "Layer 45 | Name: add_3 | Trainable: True\n",
      "Layer 46 | Name: block6_sepconv1_act | Trainable: True\n",
      "Layer 47 | Name: block6_sepconv1 | Trainable: True\n",
      "Layer 48 | Name: block6_sepconv1_bn | Trainable: True\n",
      "Layer 49 | Name: block6_sepconv2_act | Trainable: True\n",
      "Layer 50 | Name: block6_sepconv2 | Trainable: True\n",
      "Layer 51 | Name: block6_sepconv2_bn | Trainable: True\n",
      "Layer 52 | Name: block6_sepconv3_act | Trainable: True\n",
      "Layer 53 | Name: block6_sepconv3 | Trainable: True\n",
      "Layer 54 | Name: block6_sepconv3_bn | Trainable: True\n",
      "Layer 55 | Name: add_4 | Trainable: True\n",
      "Layer 56 | Name: block7_sepconv1_act | Trainable: True\n",
      "Layer 57 | Name: block7_sepconv1 | Trainable: True\n",
      "Layer 58 | Name: block7_sepconv1_bn | Trainable: True\n",
      "Layer 59 | Name: block7_sepconv2_act | Trainable: True\n",
      "Layer 60 | Name: block7_sepconv2 | Trainable: True\n",
      "Layer 61 | Name: block7_sepconv2_bn | Trainable: True\n",
      "Layer 62 | Name: block7_sepconv3_act | Trainable: True\n",
      "Layer 63 | Name: block7_sepconv3 | Trainable: True\n",
      "Layer 64 | Name: block7_sepconv3_bn | Trainable: True\n",
      "Layer 65 | Name: add_5 | Trainable: True\n",
      "Layer 66 | Name: block8_sepconv1_act | Trainable: True\n",
      "Layer 67 | Name: block8_sepconv1 | Trainable: True\n",
      "Layer 68 | Name: block8_sepconv1_bn | Trainable: True\n",
      "Layer 69 | Name: block8_sepconv2_act | Trainable: True\n",
      "Layer 70 | Name: block8_sepconv2 | Trainable: True\n",
      "Layer 71 | Name: block8_sepconv2_bn | Trainable: True\n",
      "Layer 72 | Name: block8_sepconv3_act | Trainable: True\n",
      "Layer 73 | Name: block8_sepconv3 | Trainable: True\n",
      "Layer 74 | Name: block8_sepconv3_bn | Trainable: True\n",
      "Layer 75 | Name: add_6 | Trainable: True\n",
      "Layer 76 | Name: block9_sepconv1_act | Trainable: True\n",
      "Layer 77 | Name: block9_sepconv1 | Trainable: True\n",
      "Layer 78 | Name: block9_sepconv1_bn | Trainable: True\n",
      "Layer 79 | Name: block9_sepconv2_act | Trainable: True\n",
      "Layer 80 | Name: block9_sepconv2 | Trainable: True\n",
      "Layer 81 | Name: block9_sepconv2_bn | Trainable: True\n",
      "Layer 82 | Name: block9_sepconv3_act | Trainable: True\n",
      "Layer 83 | Name: block9_sepconv3 | Trainable: True\n",
      "Layer 84 | Name: block9_sepconv3_bn | Trainable: True\n",
      "Layer 85 | Name: add_7 | Trainable: True\n",
      "Layer 86 | Name: block10_sepconv1_act | Trainable: True\n",
      "Layer 87 | Name: block10_sepconv1 | Trainable: True\n",
      "Layer 88 | Name: block10_sepconv1_bn | Trainable: True\n",
      "Layer 89 | Name: block10_sepconv2_act | Trainable: True\n",
      "Layer 90 | Name: block10_sepconv2 | Trainable: True\n",
      "Layer 91 | Name: block10_sepconv2_bn | Trainable: True\n",
      "Layer 92 | Name: block10_sepconv3_act | Trainable: True\n",
      "Layer 93 | Name: block10_sepconv3 | Trainable: True\n",
      "Layer 94 | Name: block10_sepconv3_bn | Trainable: True\n",
      "Layer 95 | Name: add_8 | Trainable: True\n",
      "Layer 96 | Name: block11_sepconv1_act | Trainable: True\n",
      "Layer 97 | Name: block11_sepconv1 | Trainable: True\n",
      "Layer 98 | Name: block11_sepconv1_bn | Trainable: True\n",
      "Layer 99 | Name: block11_sepconv2_act | Trainable: True\n",
      "Layer 100 | Name: block11_sepconv2 | Trainable: True\n",
      "Layer 101 | Name: block11_sepconv2_bn | Trainable: True\n",
      "Layer 102 | Name: block11_sepconv3_act | Trainable: True\n",
      "Layer 103 | Name: block11_sepconv3 | Trainable: True\n",
      "Layer 104 | Name: block11_sepconv3_bn | Trainable: True\n",
      "Layer 105 | Name: add_9 | Trainable: True\n",
      "Layer 106 | Name: block12_sepconv1_act | Trainable: True\n",
      "Layer 107 | Name: block12_sepconv1 | Trainable: True\n",
      "Layer 108 | Name: block12_sepconv1_bn | Trainable: True\n",
      "Layer 109 | Name: block12_sepconv2_act | Trainable: True\n",
      "Layer 110 | Name: block12_sepconv2 | Trainable: True\n",
      "Layer 111 | Name: block12_sepconv2_bn | Trainable: True\n",
      "Layer 112 | Name: block12_sepconv3_act | Trainable: True\n",
      "Layer 113 | Name: block12_sepconv3 | Trainable: True\n",
      "Layer 114 | Name: block12_sepconv3_bn | Trainable: True\n",
      "Layer 115 | Name: add_10 | Trainable: True\n",
      "Layer 116 | Name: block13_sepconv1_act | Trainable: True\n",
      "Layer 117 | Name: block13_sepconv1 | Trainable: True\n",
      "Layer 118 | Name: block13_sepconv1_bn | Trainable: True\n",
      "Layer 119 | Name: block13_sepconv2_act | Trainable: True\n",
      "Layer 120 | Name: block13_sepconv2 | Trainable: True\n",
      "Layer 121 | Name: block13_sepconv2_bn | Trainable: True\n",
      "Layer 122 | Name: conv2d_3 | Trainable: True\n",
      "Layer 123 | Name: block13_pool | Trainable: True\n",
      "Layer 124 | Name: batch_normalization_3 | Trainable: True\n",
      "Layer 125 | Name: add_11 | Trainable: True\n",
      "Layer 126 | Name: block14_sepconv1 | Trainable: True\n",
      "Layer 127 | Name: block14_sepconv1_bn | Trainable: True\n",
      "Layer 128 | Name: block14_sepconv1_act | Trainable: True\n",
      "Layer 129 | Name: block14_sepconv2 | Trainable: True\n",
      "Layer 130 | Name: block14_sepconv2_bn | Trainable: True\n",
      "Layer 131 | Name: block14_sepconv2_act | Trainable: True\n",
      "Layer 132 | Name: avg_pool | Trainable: True\n",
      "Layer 133 | Name: predictions | Trainable: True\n"
     ]
    }
   ],
   "source": [
    "print_model_properties(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transfer_model(input_size, n_categories, weights = 'imagenet'):\n",
    "        # note that the \"top\" is not included in the weights below\n",
    "        base_model = Xception(weights=weights,\n",
    "                          include_top=False,\n",
    "                          input_shape=input_size)\n",
    "        \n",
    "        model = base_model.output\n",
    "        model = GlobalAveragePooling2D()(model)\n",
    "        predictions = Dense(n_categories, activation='softmax')(model)\n",
    "        model = Model(inputs=base_model.input, outputs=predictions)\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model = create_transfer_model((299,299,3),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_trainable_layers(model, trainable_index):\n",
    "    for layer in model.layers[:trainable_index]:\n",
    "        layer.trainable = False\n",
    "    for layer in model.layers[trainable_index:]:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = change_trainable_layers(transfer_model, 132)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 130 | Name: block14_sepconv2_bn | Trainable: False\n",
      "Layer 131 | Name: block14_sepconv2_act | Trainable: False\n",
      "Layer 132 | Name: global_average_pooling2d | Trainable: True\n",
      "Layer 133 | Name: dense | Trainable: True\n"
     ]
    }
   ],
   "source": [
    "print_model_properties(transfer_model, 130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(optimizer=RMSprop(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "68/68 [==============================] - 396s 6s/step - loss: 0.1765 - accuracy: 0.9721 - val_loss: 0.0475 - val_accuracy: 0.9916\n",
      "Epoch 2/6\n",
      "68/68 [==============================] - 394s 6s/step - loss: 0.0502 - accuracy: 0.9874 - val_loss: 0.0266 - val_accuracy: 0.9958\n",
      "Epoch 3/6\n",
      "68/68 [==============================] - 394s 6s/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 0.0262 - val_accuracy: 0.9958\n",
      "Epoch 4/6\n",
      "68/68 [==============================] - 394s 6s/step - loss: 0.0330 - accuracy: 0.9902 - val_loss: 0.0229 - val_accuracy: 0.9958\n",
      "Epoch 5/6\n",
      "68/68 [==============================] - 393s 6s/step - loss: 0.0291 - accuracy: 0.9907 - val_loss: 0.0206 - val_accuracy: 0.9958\n",
      "Epoch 6/6\n",
      "68/68 [==============================] - 393s 6s/step - loss: 0.0251 - accuracy: 0.9916 - val_loss: 0.0209 - val_accuracy: 0.9958\n"
     ]
    }
   ],
   "source": [
    "transfer_test = transfer_model.fit(X_train, y_train, batch_size = 32, epochs=6, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred1 = transfer_model.predict(X_test)\n",
    "\n",
    "y_true = y_test.copy()\n",
    "\n",
    "y_true = np.array([i.argmax() for i in y_true]).reshape(-1,1)\n",
    "\n",
    "y_predicted = (pred1 > 0.5).astype(float)\n",
    "\n",
    "y_predicted = np.array([i.argmax() for i in y_predicted]).reshape(-1,1)\n",
    "\n",
    "mat = confusion_matrix(y_true, y_predicted)\n",
    "\n",
    "plot_confusion_matrix(conf_mat=mat, figsize=(8,8), class_names=folders);\n",
    "\n",
    "# plt.savefig('graphs/modelx_7_conf_mat.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Transfer Model1: Loss and Accuracy')\n",
    "evaluate = transfer_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "84/84 [==============================] - 493s 6s/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.0365 - val_accuracy: 0.9900\n",
      "Epoch 2/6\n",
      "84/84 [==============================] - 493s 6s/step - loss: 0.0168 - accuracy: 0.9948 - val_loss: 0.0370 - val_accuracy: 0.9900\n",
      "Epoch 3/6\n",
      "84/84 [==============================] - 493s 6s/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.0560 - val_accuracy: 0.9799\n",
      "Epoch 4/6\n",
      "84/84 [==============================] - 494s 6s/step - loss: 0.0132 - accuracy: 0.9963 - val_loss: 0.0462 - val_accuracy: 0.9866\n",
      "Epoch 5/6\n",
      "84/84 [==============================] - 493s 6s/step - loss: 0.0108 - accuracy: 0.9970 - val_loss: 0.0998 - val_accuracy: 0.9532\n",
      "Epoch 6/6\n",
      "84/84 [==============================] - 494s 6s/step - loss: 0.0097 - accuracy: 0.9963 - val_loss: 0.1000 - val_accuracy: 0.9565\n"
     ]
    }
   ],
   "source": [
    "xception_final = transfer_model.fit(X, y, batch_size = 32, epochs=6, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfer_model.save('saved_models/xception_final.h5')\n",
    "load_xception = tf.keras.models.load_model('saved_models/xception_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import tensorflow.keras.backend as K\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model and choose two images to explain\n",
    "vgg_model = VGG16(weights='imagenet', include_top=True)\n",
    "to_explain = X[[39,41]]\n",
    "\n",
    "# load the ImageNet class names\n",
    "# url = \"https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\"\n",
    "# fname = shap.datasets.cache(url)\n",
    "# with open(fname) as f:\n",
    "#     class_names = json.load(f)\n",
    "\n",
    "# explain how the input to the 7th layer of the model explains the top two classes\n",
    "def map2layer(x, layer):\n",
    "    feed_dict = dict(zip([vgg_model.layers[0].input], [preprocess_input(x.copy())]))\n",
    "    return K.get_session().run(model.layers[layer].input, feed_dict)\n",
    "e = shap.GradientExplainer(\n",
    "    (model.layers[7].input, model.layers[-1].output),\n",
    "    map2layer(X, 7),\n",
    "    local_smoothing=0 # std dev of smoothing noise\n",
    ")\n",
    "shap_values,indexes = e.shap_values(map2layer(to_explain, 7), ranked_outputs=2)\n",
    "\n",
    "# get the names for the classes\n",
    "# index_names = np.vectorize(lambda x: class_names[str(x)][1])(indexes)\n",
    "\n",
    "# plot the explanations\n",
    "shap.image_plot(shap_values, to_explain, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
